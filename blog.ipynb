{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Interactive Access and Visualization of Geospatial Data from the AWS Open Data Program\n",
    "\n",
    "**By Qiusheng Wu, Matt Putkoski, and Chris Stoner**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Open data is reshaping how we understand and respond to global challenges. From climate change to disaster recovery, the ability to access and analyze large-scale geospatial datasets is critical for scientific research, policy-making, and real-world applications. Leading the charge are several open data initiatives designed to lower access barriers and accelerate innovation: the [AWS Open Data Program](https://aws.amazon.com/opendata), the [Amazon Sustainability Data Initiative (ASDI)](https://exchange.aboutamazon.com/data-initiative), and the [Maxar Open Data Program](https://registry.opendata.aws/maxar-open-data).\n",
    "\n",
    "The **AWS Open Data Program** hosts a diverse range of high-value datasets—from satellite imagery and climate models to genomics and machine learning benchmarks—on Amazon Web Services. These datasets are freely accessible and stored in Amazon S3, enabling cloud-native analysis without requiring massive local downloads. Researchers and developers can process data directly in the cloud using scalable tools like Amazon Athena, SageMaker, and open-source Python libraries. The registry of AWS Open Data is available at [https://registry.opendata.aws](https://registry.opendata.aws).\n",
    "\n",
    "Building on this foundation, the **Amazon Sustainability Data Initiative (ASDI)** focuses specifically on environmental and sustainability-related datasets. ASDI supports global research efforts by providing open access to critical data such as weather forecasts, satellite observations, air quality indices, and hydrological models. These resources help drive solutions in areas such as climate resilience, renewable energy, conservation, and disaster risk management. ASDI also collaborates with organizations like NASA, NOAA, and the UN to make authoritative datasets readily available through AWS. The registry of ASDI is available at [https://registry.opendata.aws/collab/asdi](https://registry.opendata.aws/collab/asdi).\n",
    "\n",
    "The **Maxar Open Data Program**, meanwhile, provides high-resolution satellite imagery in the aftermath of natural disasters and humanitarian crises. Unlike continuous monitoring programs, Maxar's initiative is event-driven—activated during emergencies such as hurricanes, wildfires, earthquakes, and conflicts. By releasing timely, publicly available imagery, Maxar empowers responders, analysts, and volunteers with actionable insights for damage assessment, response coordination, and recovery planning. More information about Maxar Open Data is available at [https://registry.opendata.aws/maxar-open-data](https://registry.opendata.aws/maxar-open-data/).\n",
    "\n",
    "Together, these programs demonstrate the power of cloud-enabled open data to democratize access to geospatial information, promote global collaboration, and drive real-world impact. In this post, we demonstrate how to explore and visualize these datasets using interactive web applications and Jupyter notebooks.\n",
    "\n",
    "## Interactive Web Applications for Geospatial Data Exploration\n",
    "\n",
    "To make these datasets more accessible to a wider audience, we’ve developed two interactive web applications that simplify data discovery and visualization. Built with Python and modern web technologies, these tools allow users to explore AWS and Maxar open data directly in the browser.\n",
    "\n",
    "### 1. Amazon ASDI Data Explorer\n",
    "\n",
    "The **Amazon ASDI Data Explorer** provides a user-friendly interface for browsing and visualizing datasets available through ASDI and the broader AWS Open Data Program. Key features include:\n",
    "\n",
    "- Catalog browsing with spatial and temporal filtering\n",
    "- STAC-based search for satellite and environmental data\n",
    "- Interactive map-based visualization\n",
    "\n",
    "This Amazon ASDI Data Explorer is powered by [Leafmap](https://leafmap.org), an open-source Python package for interactive visualization of geospatial data, and deployed using the [Solara](https://solara.dev) web framework on [Hugging Face Spaces](https://huggingface.co/spaces).\n",
    "\n",
    "The web app and the source code are available at:\n",
    "\n",
    "- Web app: <https://huggingface.co/spaces/giswqs/Amazon-ASDI>\n",
    "- GitHub: <https://github.com/opengeos/Amazon-ASDI>\n",
    "\n",
    "![Amazon ASDI Data Explorer](https://github.com/user-attachments/assets/ad4f484f-e0ef-4c78-9027-694e9b3d6a93)\n",
    "**Figure 1.** The Amazon ASDI Data Explorer allows users to search and visualize Amazon ASDI datasets interactively.\n",
    "\n",
    "**How to use:**\n",
    "\n",
    "1. Visit the [Amazon ASDI Data Explorer](https://huggingface.co/spaces/giswqs/Amazon-ASDI).\n",
    "2. Click on the “ASDI” tab to launch the interactive map.\n",
    "3. Zoom and pan to your region of interest. Optionally, you can use the drawing tool to draw a polygon on the map to select a region of interest.\n",
    "4. In the STAC Search sidebar, choose “AWS Open Data” as the catalog source.\n",
    "5. Select a dataset (e.g., _10m Annual Land Use Land Cover_) and customize the date range as needed.\n",
    "6. Click on the “Search” button to search for the datasets. The footprints of the available datasets will be displayed on the map.\n",
    "7. Select an item from the search results and click on the “Display” button to overlay the data on the map.\n",
    "8. Use the Layers panel to adjust layer visibility and opacity.\n",
    "9. Repeat steps 2-8 to search and visualize other datasets or change the region of interest.\n",
    "\n",
    "This workflow allows users to access and explore complex geospatial datasets in just a few clicks—ideal for educators, researchers, and analysts alike.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Maxar Open Data Explorer\n",
    "\n",
    "The **Maxar Open Data Explorer** focuses on disaster response and humanitarian mapping by providing interactive access to event-based satellite imagery released through the Maxar Open Data Program. Key features include:\n",
    "\n",
    "- Browse available disaster events\n",
    "- View satellite image footprints on the map\n",
    "- Compare pre- and post-disaster imagery side by side\n",
    "\n",
    "This Maxar Open Data Explorer is powered by [Leafmap](https://leafmap.org) and deployed using the [Solara](https://solara.dev) web framework on [Hugging Face Spaces](https://huggingface.co/spaces).\n",
    "\n",
    "The web app and the source code are available at:\n",
    "\n",
    "- Web app: <https://huggingface.co/spaces/giswqs/solara-maxar>\n",
    "- GitHub: <https://github.com/opengeos/solara-maxar>\n",
    "\n",
    "![Maxar Open Data Explorer](https://github.com/user-attachments/assets/94938ae5-bd76-4d26-964f-91c71c48c93f)\n",
    "**Figure 2.** The Maxar Open Data Explorer allows users to visualize and compare Maxar satellite imagery for disaster events.\n",
    "\n",
    "**How to use:**\n",
    "\n",
    "1. Visit the [Maxar Open Data Explorer](https://huggingface.co/spaces/giswqs/solara-maxar).\n",
    "2. Choose an event (e.g., _Libya_) from menu tab.\n",
    "3. The application displays the imagery footprints on the map.\n",
    "4. Pick a start date to filter the imagery taken after the start date.\n",
    "5. Hover over any footprint to view its metadata displayed in the information panel in the lower left corner.\n",
    "6. Click on any footprint to view the satellite imagery.\n",
    "7. Use the Layers panel to control visibility and opacity.\n",
    "8. Toggle the “Split map” option to compare before-and-after images.\n",
    "\n",
    "This tool is especially useful for emergency responders, humanitarian agencies, and open-source mapping communities involved in real-time crisis mapping and assessment.\n",
    "\n",
    "## Accessing and Visualizing Maxar Open Data in Jupyter Notebook\n",
    "\n",
    "[Leafmap](https://leafmap.org) is a Python package that makes it easy to visualize and analyze geospatial data interactively. It provides seamless integration with AWS S3, STAC catalogs, and various geospatial data formats. With Leafmap, you can create interactive maps, perform geospatial analysis, and visualize results—all within a few lines of Python code.\n",
    "\n",
    "### Installation\n",
    "\n",
    "Before we begin exploring the datasets, let's install Leafmap. If you're running this in a Jupyter notebook, you can run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install leafmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "This will install Leafmap and its dependencies, including support for various geospatial data formats, cloud-optimized imagery, and interactive mapping capabilities.\n",
    "\n",
    "### Importing Libraries\n",
    "\n",
    "Now let's dive into a practical example of accessing and visualizing Maxar Open Data. We'll start by importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leafmap\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Here, we're importing `leafmap` for geospatial visualization and `geopandas` for working with geospatial data structures. GeoPandas extends the popular pandas library to handle geographic data efficiently.\n",
    "\n",
    "### Discovering Available Disaster Events\n",
    "\n",
    "The first step is to explore what disaster events are available in the Maxar Open Data catalog. Each collection in the catalog represents a single disaster event with associated satellite imagery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "leafmap.maxar_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "This function retrieves all available collections from the Maxar Open Data STAC (SpatioTemporal Asset Catalog) catalog. The output will show you a list of disaster events, each with a unique collection ID that we can use to access the specific imagery data.\n",
    "\n",
    "### Selecting a Disaster Event\n",
    "\n",
    "For this example, we'll focus on the devastating earthquake that struck Turkey and Syria in February 2023. The collection ID for this event is `Kahramanmaras-turkey-earthquake-23`. We can retrieve the geographic footprints of all available satellite images for this event from the [Maxar Open Data GitHub repository](https://github.com/opengeos/maxar-open-data), which provides both GeoJSON and TSV formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"Kahramanmaras-turkey-earthquake-23\"\n",
    "url = leafmap.maxar_collection_url(collection, dtype=\"geojson\")\n",
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "This function generates a URL pointing to the GeoJSON file containing the spatial footprints and metadata for all satellite images related to the Turkey earthquake event. The GeoJSON format is particularly useful because it includes both the geographic boundaries of each image and associated metadata.\n",
    "\n",
    "Now let's load this data and explore what's available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(url)\n",
    "print(f\"Total number of images: {len(gdf)}\")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Here we're using GeoPandas to read the remote GeoJSON file directly from the URL. The `gdf.head()` command shows us the first few rows of the dataset, revealing important metadata columns such as:\n",
    "\n",
    "- **geometry**: The spatial footprint of each satellite image\n",
    "- **catalog_id**: A unique identifier for grouping related images\n",
    "- **quadkey**: Microsoft's quadkey system for tile identification\n",
    "- **timestamp**: When the image was captured\n",
    "- **visual**: Direct download link to the satellite image\n",
    "- **event_name**: The disaster event name\n",
    "\n",
    "### Visualizing Image Footprints\n",
    "\n",
    "Now let's create an interactive map to visualize where all these satellite images are located geographically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = leafmap.Map()\n",
    "m.add_gdf(gdf, layer_name=\"Footprints\", zoom_to_layer=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "![image](https://github.com/user-attachments/assets/13184223-b5cc-4868-836b-39dbb05cdd70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "This creates an interactive map centered on the earthquake region, with blue polygons showing the spatial coverage of each satellite image. You can zoom in, pan around, and click on individual footprints to see their metadata. This visualization helps us understand the geographic extent of the available imagery and identify areas with dense coverage.\n",
    "\n",
    "### Temporal Analysis: Before and After the Earthquake\n",
    "\n",
    "The earthquake struck on February 6, 2023, making temporal analysis crucial for damage assessment. Let's separate the imagery into pre-event and post-event datasets using the earthquake date as our temporal boundary.\n",
    "\n",
    "First, let's get all images captured before the earthquake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_gdf = leafmap.maxar_search(collection, end_date=\"2023-02-06\")\n",
    "print(f\"Total number of pre-event images: {len(pre_gdf)}\")\n",
    "pre_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "The `leafmap.maxar_search()` function allows us to filter the imagery collection by date. By setting `end_date=\"2023-02-06\"`, we retrieve only images captured before the earthquake occurred. These pre-event images serve as our baseline for comparison.\n",
    "\n",
    "Now let's get all images captured after the earthquake:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_gdf = leafmap.maxar_search(collection, start_date=\"2023-02-06\")\n",
    "print(f\"Total number of post-event images: {len(post_gdf)}\")\n",
    "post_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "By setting `start_date=\"2023-02-06\"`, we retrieve all images captured from the earthquake date onwards. These post-event images will show the immediate aftermath and damage caused by the earthquake.\n",
    "\n",
    "### Comparing Pre-Event and Post-Event Coverage\n",
    "\n",
    "Let's create a comparative visualization showing both pre-event and post-event image footprints on the same map:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = leafmap.Map()\n",
    "pre_style = {\"color\": \"red\", \"fillColor\": \"red\", \"opacity\": 1, \"fillOpacity\": 0.5}\n",
    "m.add_gdf(\n",
    "    pre_gdf,\n",
    "    layer_name=\"Pre-event\",\n",
    "    style=pre_style,\n",
    "    info_mode=\"on_click\",\n",
    "    zoom_to_layer=True,\n",
    ")\n",
    "m.add_gdf(post_gdf, layer_name=\"Post-event\", info_mode=\"on_click\", zoom_to_layer=True)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "![image](https://github.com/user-attachments/assets/7c41b716-1b13-4754-857d-9df084e8bc26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "In this visualization, red polygons represent pre-earthquake imagery while blue polygons show post-earthquake coverage. The `info_mode=\"on_click\"` parameter enables interactive information popups when you click on any footprint. You can toggle layers on/off using the layer control panel, and the different colors help distinguish the temporal coverage patterns.\n",
    "\n",
    "### Selecting a Region of Interest\n",
    "\n",
    "To focus our analysis on a specific area, we can define a region of interest (ROI). You can either draw a polygon on the map using the drawing tools, or we'll use predefined coordinates for a particularly affected area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = m.user_roi_bounds()\n",
    "if bbox is None:\n",
    "    bbox = [36.8715, 37.5497, 36.9814, 37.6019]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "The `m.user_roi_bounds()` function attempts to get the bounding box coordinates from any region you've drawn on the map. If no region is drawn, we fall back to predefined coordinates that cover a significantly impacted area near Kahramanmaraş. The bbox format follows [min_longitude, min_latitude, max_longitude, max_latitude] convention.\n",
    "\n",
    "### Searching Within the Region of Interest\n",
    "\n",
    "Now let's search for satellite images that specifically cover our region of interest, filtering by both geographic bounds and temporal constraints.\n",
    "\n",
    "First, let's find pre-earthquake images within our ROI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_event = leafmap.maxar_search(collection, bbox=bbox, end_date=\"2023-02-06\")\n",
    "pre_event.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "This search combines spatial filtering (using the bounding box) with temporal filtering (images before February 6, 2023). The result shows us only images that both intersect our geographic area of interest and were captured before the earthquake.\n",
    "\n",
    "Similarly, let's find post-earthquake images within the same area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_event = leafmap.maxar_search(collection, bbox=bbox, start_date=\"2023-02-06\")\n",
    "post_event.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "This gives us the corresponding post-earthquake imagery for the same geographic region, enabling direct before-and-after comparison.\n",
    "\n",
    "### Preparing Images for Visualization\n",
    "\n",
    "Maxar organizes satellite images into tiles, where each tile can contain multiple individual images identified by unique quadkeys. Let's extract the tile identifiers we need for visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tile = pre_event[\"catalog_id\"].values[0]\n",
    "pre_tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "This gets the catalog ID for the first pre-event tile in our search results. The catalog ID serves as a unique identifier for a collection of related satellite images covering the same geographic area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_tile = post_event[\"catalog_id\"].values[0]\n",
    "post_tile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Similarly, this extracts the catalog ID for the post-event tile. Having both pre- and post-event tile IDs allows us to create comparative visualizations.\n",
    "\n",
    "### Creating Web-Optimized Tile Services\n",
    "\n",
    "To display these high-resolution satellite images efficiently in a web browser, we need to convert them to MosaicJSON format, which enables dynamic tiling and streaming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_stac = leafmap.maxar_tile_url(collection, pre_tile, dtype=\"json\")\n",
    "pre_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "This generates a MosaicJSON URL for the pre-event tile. MosaicJSON is a specification that allows multiple raster files to be presented as a single web-optimized layer, enabling efficient visualization of large satellite imagery datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_stac = leafmap.maxar_tile_url(collection, post_tile, dtype=\"json\")\n",
    "post_stac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Similarly, this creates the MosaicJSON URL for the post-event imagery. These URLs point to tile services that can stream the imagery directly to our interactive map.\n",
    "\n",
    "### Creating a Split-Screen Comparison\n",
    "\n",
    "Now comes the powerful part—creating a side-by-side comparison to visualize the earthquake's impact:\n",
    "\n",
    "We re-import leafmap to ensure we're using the latest configuration (particularly important for the folium backend which handles split maps better than ipyleaflet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = leafmap.Map()\n",
    "m.split_map(\n",
    "    left_layer=pre_stac,\n",
    "    right_layer=post_stac,\n",
    "    left_label=\"Pre-event\",\n",
    "    right_label=\"Post-event\",\n",
    ")\n",
    "m.set_center(36.9265, 37.5762, 16)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "![image](https://github.com/user-attachments/assets/1a43a737-e9ff-4c9d-b301-ff4c37787d44)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "This creates an interactive split-screen map where you can:\n",
    "\n",
    "- **Left side**: View the area before the earthquake\n",
    "- **Right side**: View the same area after the earthquake\n",
    "- **Divider**: Drag the vertical divider left or right to compare different parts of the scene\n",
    "- **Synchronization**: Both sides pan and zoom together, maintaining perfect geographic alignment\n",
    "\n",
    "The `m.set_center()` function centers the map on the most impacted area at zoom level 16, providing detailed street-level view of the earthquake damage.\n",
    "\n",
    "### Downloading Images for Offline Analysis\n",
    "\n",
    "If you need to perform detailed analysis or store images locally, you can download the original high-resolution imagery:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_images = pre_event[\"visual\"].tolist()\n",
    "post_images = post_event[\"visual\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "This extracts the direct download URLs from our filtered datasets. The \"visual\" column contains links to the processed, analysis-ready satellite images in RGB format that are optimized for visual interpretation.\n",
    "\n",
    "Now let's download the pre-event images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "leafmap.maxar_download(pre_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "The `leafmap.maxar_download()` function handles the download process, saving images to your local directory with organized naming conventions. These high-resolution images can then be used for:\n",
    "\n",
    "- Detailed damage assessment\n",
    "- Machine learning training datasets\n",
    "- Offline mapping applications\n",
    "- Scientific research and analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leafmap.maxar_download(post_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "The post-event images are commented out to avoid long download times in this example, but you can uncomment this line to download the post-earthquake imagery as well. Each image is typically several megabytes in size, so consider your bandwidth and storage constraints when downloading large datasets.\n",
    "\n",
    "## Conclusions\n",
    "\n",
    "Access to high-quality geospatial data is no longer limited to technical experts with large computing resources. Thanks to open data initiatives like the AWS Open Data Program, ASDI, and the Maxar Open Data Program, coupled with intuitive tools like Leafmap and Solara, anyone can explore and visualize critical Earth data in minutes.\n",
    "\n",
    "Whether you're a researcher investigating climate trends, a student exploring land cover dynamics, or a volunteer aiding in disaster mapping, these tools offer a powerful gateway to cloud-hosted open data—turning raw datasets into actionable insight."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "default_lexer": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
